{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgs\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchsummary import summary as summary\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset): \n",
    "    def __init__(self, x_data, y_data, transform=None):\n",
    "        # self.x_train = np.array(x_data)\n",
    "        self.y_train = np.array(y_data)\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data \n",
    "        self.transform = transform\n",
    "        self.target_transform = ToTensor()\n",
    "        self.idx = 0\n",
    "    def __len__(self):\n",
    "            return len(self.x_data)\n",
    "    def __getitem__(self, idx):\n",
    "            if self.transform:\n",
    "                x = self.transform(self.x_data[idx])\n",
    "                self.idx = idx \n",
    "            if self.target_transform:\n",
    "                y = torch.from_numpy(np.array(self.y_train[idx])).float()\n",
    "            return x, y\n",
    "    def __idx__(self):\n",
    "        return self.x_data[self.idx]\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        output_channel = 512\n",
    "        input_channel = 10\n",
    "        self.output_channel = [int(output_channel / 8), int(output_channel / 4),\n",
    "        int(output_channel / 2), output_channel]  # [64, 128, 256, 512]\n",
    "        \n",
    "        self.ConvNet = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channel, out_channels=self.output_channel[0], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),  # 64x16x50\n",
    "            nn.Conv2d(in_channels=self.output_channel[0], out_channels=self.output_channel[1], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),  # 128x8x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[1], out_channels=self.output_channel[2],kernel_size=3, stride=1, padding=1), nn.ReLU(True),  # 256x8x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[2], out_channels=self.output_channel[2], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)),  # 256x4x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[2], out_channels=self.output_channel[3], kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.output_channel[3]), nn.ReLU(True),  # 512x4x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[3], out_channels=self.output_channel[3], kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.output_channel[3]), nn.ReLU(True),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)),  # 512x2x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[3], out_channels=self.output_channel[3], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)))  # 512x1x24\n",
    "            # nn.AdaptiveAvgPool2d((1, 1)))\n",
    "        self.fc_layer = nn.Sequential(\n",
    "        \t# [100,64*3*3] -> [100,100]\n",
    "            nn.Linear(65536,4096),                                              \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,1000),  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1000,3),                             \n",
    "        )     \n",
    "    def forward(self, x):\n",
    "        out = self.ConvNet(x)\n",
    "        out = torch.flatten(out, 1) # 배치를 제외한 모든 차원을 평탄화(flatten)\n",
    "        out = self.fc_layer(out)\n",
    "        return out\n",
    "\n",
    "class NeuralNetwork2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork2, self).__init__()\n",
    "        output_channel = 512\n",
    "        input_channel = 3\n",
    "        self.output_channel = [int(output_channel / 8), int(output_channel / 4),\n",
    "        int(output_channel / 2), output_channel]  # [64, 128, 256, 512]\n",
    "        \n",
    "        self.ConvNet = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channel, out_channels=self.output_channel[0], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),  # 64x16x50\n",
    "            nn.Conv2d(in_channels=self.output_channel[0], out_channels=self.output_channel[1], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),  # 128x8x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[1], out_channels=self.output_channel[2],kernel_size=3, stride=1, padding=1), nn.ReLU(True),  # 256x8x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[2], out_channels=self.output_channel[2], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)),  # 256x4x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[2], out_channels=self.output_channel[3], kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.output_channel[3]), nn.ReLU(True),  # 512x4x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[3], out_channels=self.output_channel[3], kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.output_channel[3]), nn.ReLU(True),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)),  # 512x2x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[3], out_channels=self.output_channel[3], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)),  # 512x1x24\n",
    "            nn.AdaptiveAvgPool2d((1, 1)))\n",
    "        self.fc_layer = nn.Sequential(\n",
    "        \t# [100,64*3*3] -> [100,100]\n",
    "            # nn.Linear(65536,4096),                                              \n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            # nn.Linear(4096,1000),  \n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(512,3),                             \n",
    "        )     \n",
    "    def forward(self, x):\n",
    "        out = self.ConvNet(x)\n",
    "        out = torch.flatten(out, 1) # 배치를 제외한 모든 차원을 평탄화(flatten)\n",
    "        out = self.fc_layer(out)\n",
    "        return out\n",
    "        \n",
    "    \n",
    "def file_recursively(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if((os.path.join(root,file).find(\".jpg\")) != -1):\n",
    "                list_root.append(os.path.join(root ,file))\n",
    "             \n",
    "def train_test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            y = y.to(device)\n",
    "            output = model.forward(x)\n",
    "            loss = loss_fn(output,y)\n",
    "            test_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= size\n",
    "    print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(dataloader.dataset), 100. * correct / len(dataloader.dataset)))\n",
    "    f.write('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(dataloader.dataset), 100. * correct / len(dataloader.dataset)))\n",
    "      \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            y = y.to(device)\n",
    "            output = model.forward(x)\n",
    "            loss = loss_fn(output,y)\n",
    "            test_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= size\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(dataloader.dataset), 100. * correct / len(dataloader.dataset)))\n",
    "    f.write('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(dataloader.dataset), 100. * correct / len(dataloader.dataset)))\n",
    "    return test_loss\n",
    "if __name__ == '__main__':\n",
    "                     \n",
    "    device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    "\n",
    "    print(f\"Using {device} device\")   \n",
    "\n",
    "    list_root = []\n",
    "    dic = {}\n",
    "    list_root_label = []\n",
    "\n",
    "    file_recursively('E:/동현_개인폴더/대회/USG제조혁신대회2차_2/2/train_data')\n",
    "    \n",
    "    for i in list_root:\n",
    "        if i.find(\"capacitor\") != -1:\n",
    "            dic[i] = 1\n",
    "        elif i.find(\"IC\") != -1:\n",
    "            dic[i] = 0\n",
    "        elif i.find(\"resistor\") != -1:\n",
    "            dic[i] = 2\n",
    "\n",
    "            \n",
    "        list_root_label.append(dic[i])    \n",
    "\n",
    "    img_end = []\n",
    "    img_end2 = []\n",
    "    \n",
    "    for i in list_root:\n",
    "        # img = imgs.imread(i)\n",
    "        img = Image.open(i).convert(\"RGB\")\n",
    "        # img = cv2.resize(img, dsize=(640,640), interpolation=cv2.INTER_LINEAR)\n",
    "        min_value = np.min(img)\n",
    "        max_value = np.max(img)\n",
    "        output = (img - min_value) / (max_value - min_value)\n",
    "        img_end.append(output)\n",
    "        img_end2.append(img)\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(img_end2, list_root_label, test_size= 0.2, random_state= 33 ,shuffle=True)\n",
    "            \n",
    "            \n",
    "            \n",
    "    batch_size = 2\n",
    "\n",
    "\n",
    "    transforms_train = transforms.Compose([ transforms.Resize((128, 128)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        # transforms.RandomRotation(10.)\n",
    "                                        ])\n",
    "\n",
    "    transforms_test = transforms.Compose([transforms.Resize((128,128)),\n",
    "                                        transforms.ToTensor()\n",
    "                                        ])\n",
    "\n",
    "\n",
    "    dataset_train = CustomDataset(x_train, y_train, transform=transforms_train)\n",
    "    dataset_valid = CustomDataset(x_valid, y_valid, transform=transforms_test)\n",
    "\n",
    "\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "    dataloader_valid = DataLoader(dataset_valid, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "    model = NeuralNetwork2().to(device)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) \n",
    "\n",
    "    print(dataloader_train)\n",
    "\n",
    "\n",
    "    learning_rate = 1e-5\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    # dataloader_train = dataloader_train.squeeze(dim=0)\n",
    "    nb_epochs = 100\n",
    "    txtName = \"modelTrainLog\"\n",
    "    count = 0\n",
    "    best_loss = 10 ** 9 # 매우 큰 값으로 초기값 가정\n",
    "    patience_limit = 10 # 몇 번의 epoch까지 지켜볼지를 결정\n",
    "    patience_check = 0 # 현재 몇 epoch 연속으로 loss 개선이 안되는지를 기록\n",
    "    while(True):\n",
    "        if os.path.isfile(\"./model/{} ({}).txt\".format(txtName, count)) != True:\n",
    "            f = open(\"./model/{} ({}).txt\".format(txtName, count), \"w\")\n",
    "            break\n",
    "        else:\n",
    "            count += 1\n",
    "    summary(model, (3,128, 128))\n",
    "    f.write(f\"batchsize: {batch_size:>d} epochs: {nb_epochs:>d}\\n\\n\")\n",
    "\n",
    "    for epoch in range(nb_epochs + 1):\n",
    "        for batch, (x, y) in enumerate(dataloader_train):\n",
    "            x_train = x.to(device)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            y_train = y.to(device)\n",
    "            # H(x) 계산\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model.forward(x_train)\n",
    "            \n",
    "            loss = loss_func(pred, y_train)\n",
    "         \n",
    "            # 역전파\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch % 1000 == 0:\n",
    "                loss, current = loss.item(), (batch + 1) * len(x_train)\n",
    "                # print(f\"[epoch: {epoch:>5d}] loss: {loss:>7f}\")\n",
    "                print(f\"[epoch: {epoch:>d}] loss: {loss:>7f}  [{current:>5d}/{len(dataset_train.x_data):>5d}]\")\n",
    "                f.write(f\"[epoch: {epoch:>d}] loss: {loss:>7f}  [{current:>5d}/{len(dataset_train.x_data):>5d}]\\n\")\n",
    "        train_test(dataloader_train, model, loss_func)   \n",
    "        val_loss = test(dataloader_valid, model, loss_func)\n",
    "        model.eval()\n",
    "            \n",
    "        ### early stopping 여부를 체크하는 부분 ###\n",
    "        if val_loss > best_loss: # loss가 개선되지 않은 경우\n",
    "            patience_check += 1\n",
    "            if patience_check >= 6:\n",
    "                learning_rate = learning_rate / 2\n",
    "            if patience_check >= patience_limit: # early stopping 조건 만족 시 조기 종료\n",
    "                break\n",
    "        else:\n",
    "            best_loss = val_loss\n",
    "            patience_check = 0\n",
    "        PATH = './model/vgg_net_check_point.pth'\n",
    "        torch.save(model, PATH)\n",
    "        \n",
    "    PATH = './model/image.pth'\n",
    "    torch.save(model, PATH)\n",
    "    PATH = './model/image_best.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "        \n",
    "    model.eval()\n",
    "\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        count = 0\n",
    "        for x,y in dataloader_valid:\n",
    "            x = x.to(device)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            y = y.to(device)\n",
    "            outputs = model.forward(x)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += len(y)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            # for i in range(0, len(y)):\n",
    "            #     if(predicted[i].item() != y[i]):\n",
    "            #         plt.axis('off')\n",
    "            #         tf = transforms.ToPILImage()\n",
    "            #         img = tf(x[i])\n",
    "            #         plt.imshow(img)\n",
    "            #         plt.savefig('./mis2/{}_{}_{}.jpg'.format(count,y[i], predicted[i].item()),format='jpeg',bbox_inches=\"tight\", pad_inches = 0)\n",
    "            #     count += 1\n",
    "        print('Test Accuracy of the model on the {} test images: {} %'.format(total, 100 * correct / total))\n",
    "        f.write('Test Accuracy of the model on the {} test images: {} %\\n'.format(total, 100 * correct / total))\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
