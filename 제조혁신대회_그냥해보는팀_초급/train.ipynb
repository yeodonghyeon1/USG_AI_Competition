{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000002A47E060550>\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           1,792\n",
      "              ReLU-2         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-3           [-1, 64, 64, 64]               0\n",
      "            Conv2d-4          [-1, 128, 64, 64]          73,856\n",
      "              ReLU-5          [-1, 128, 64, 64]               0\n",
      "         MaxPool2d-6          [-1, 128, 32, 32]               0\n",
      "            Conv2d-7          [-1, 256, 32, 32]         295,168\n",
      "              ReLU-8          [-1, 256, 32, 32]               0\n",
      "            Conv2d-9          [-1, 256, 32, 32]         590,080\n",
      "             ReLU-10          [-1, 256, 32, 32]               0\n",
      "        MaxPool2d-11          [-1, 256, 16, 32]               0\n",
      "           Conv2d-12          [-1, 512, 16, 32]       1,179,648\n",
      "      BatchNorm2d-13          [-1, 512, 16, 32]           1,024\n",
      "             ReLU-14          [-1, 512, 16, 32]               0\n",
      "           Conv2d-15          [-1, 512, 16, 32]       2,359,296\n",
      "      BatchNorm2d-16          [-1, 512, 16, 32]           1,024\n",
      "             ReLU-17          [-1, 512, 16, 32]               0\n",
      "        MaxPool2d-18           [-1, 512, 8, 32]               0\n",
      "           Conv2d-19           [-1, 512, 8, 32]       2,359,808\n",
      "             ReLU-20           [-1, 512, 8, 32]               0\n",
      "        MaxPool2d-21           [-1, 512, 4, 32]               0\n",
      "           Linear-22                 [-1, 4096]     268,439,552\n",
      "             ReLU-23                 [-1, 4096]               0\n",
      "          Dropout-24                 [-1, 4096]               0\n",
      "           Linear-25                 [-1, 1000]       4,097,000\n",
      "             ReLU-26                 [-1, 1000]               0\n",
      "          Dropout-27                 [-1, 1000]               0\n",
      "           Linear-28                    [-1, 2]           2,002\n",
      "================================================================\n",
      "Total params: 279,400,250\n",
      "Trainable params: 279,400,250\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 51.62\n",
      "Params size (MB): 1065.83\n",
      "Estimated Total Size (MB): 1117.63\n",
      "----------------------------------------------------------------\n",
      "[epoch: 0] loss: 0.760644  [    2/ 4800]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\동현_개인폴더\\대회\\USG제조혁신대회2차\\train.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/%EB%8F%99%ED%98%84_%EA%B0%9C%EC%9D%B8%ED%8F%B4%EB%8D%94/%EB%8C%80%ED%9A%8C/USG%EC%A0%9C%EC%A1%B0%ED%98%81%EC%8B%A0%EB%8C%80%ED%9A%8C2%EC%B0%A8/train.ipynb#W0sZmlsZQ%3D%3D?line=274'>275</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nb_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/%EB%8F%99%ED%98%84_%EA%B0%9C%EC%9D%B8%ED%8F%B4%EB%8D%94/%EB%8C%80%ED%9A%8C/USG%EC%A0%9C%EC%A1%B0%ED%98%81%EC%8B%A0%EB%8C%80%ED%9A%8C2%EC%B0%A8/train.ipynb#W0sZmlsZQ%3D%3D?line=275'>276</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch, (x, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader_train):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/e%3A/%EB%8F%99%ED%98%84_%EA%B0%9C%EC%9D%B8%ED%8F%B4%EB%8D%94/%EB%8C%80%ED%9A%8C/USG%EC%A0%9C%EC%A1%B0%ED%98%81%EC%8B%A0%EB%8C%80%ED%9A%8C2%EC%B0%A8/train.ipynb#W0sZmlsZQ%3D%3D?line=276'>277</a>\u001b[0m         x_train \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/%EB%8F%99%ED%98%84_%EA%B0%9C%EC%9D%B8%ED%8F%B4%EB%8D%94/%EB%8C%80%ED%9A%8C/USG%EC%A0%9C%EC%A1%B0%ED%98%81%EC%8B%A0%EB%8C%80%ED%9A%8C2%EC%B0%A8/train.ipynb#W0sZmlsZQ%3D%3D?line=277'>278</a>\u001b[0m         y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mLongTensor)\n\u001b[0;32m    <a href='vscode-notebook-cell:/e%3A/%EB%8F%99%ED%98%84_%EA%B0%9C%EC%9D%B8%ED%8F%B4%EB%8D%94/%EB%8C%80%ED%9A%8C/USG%EC%A0%9C%EC%A1%B0%ED%98%81%EC%8B%A0%EB%8C%80%ED%9A%8C2%EC%B0%A8/train.ipynb#W0sZmlsZQ%3D%3D?line=278'>279</a>\u001b[0m         y_train \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgs\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchsummary import summary as summary\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset): \n",
    "    def __init__(self, x_data, y_data, transform=None):\n",
    "        # self.x_train = np.array(x_data)\n",
    "        self.y_train = np.array(y_data)\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data \n",
    "        self.transform = transform\n",
    "        self.target_transform = ToTensor()\n",
    "        self.idx = 0\n",
    "    def __len__(self):\n",
    "            return len(self.x_data)\n",
    "    def __getitem__(self, idx):\n",
    "            if self.transform:\n",
    "                x = self.transform(self.x_data[idx])\n",
    "                self.idx = idx \n",
    "            if self.target_transform:\n",
    "                y = torch.from_numpy(np.array(self.y_train[idx])).float()\n",
    "            return x, y\n",
    "    def __idx__(self):\n",
    "        return self.x_data[self.idx]\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        output_channel = 512\n",
    "        input_channel = 3\n",
    "        self.output_channel = [int(output_channel / 8), int(output_channel / 4),\n",
    "        int(output_channel / 2), output_channel]  # [64, 128, 256, 512]\n",
    "        \n",
    "        self.ConvNet = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channel, out_channels=self.output_channel[0], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),  # 64x16x50\n",
    "            nn.Conv2d(in_channels=self.output_channel[0], out_channels=self.output_channel[1], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),  # 128x8x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[1], out_channels=self.output_channel[2],kernel_size=3, stride=1, padding=1), nn.ReLU(True),  # 256x8x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[2], out_channels=self.output_channel[2], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)),  # 256x4x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[2], out_channels=self.output_channel[3], kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.output_channel[3]), nn.ReLU(True),  # 512x4x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[3], out_channels=self.output_channel[3], kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.output_channel[3]), nn.ReLU(True),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)),  # 512x2x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[3], out_channels=self.output_channel[3], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)))  # 512x1x24\n",
    "            # nn.AdaptiveAvgPool2d((1, 1)))\n",
    "        self.fc_layer = nn.Sequential(\n",
    "        \t# [100,64*3*3] -> [100,100]\n",
    "            nn.Linear(65536,4096),                                              \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096,1000),  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1000,2),                             \n",
    "        )     \n",
    "    def forward(self, x):\n",
    "        out = self.ConvNet(x)\n",
    "        out = torch.flatten(out, 1) # 배치를 제외한 모든 차원을 평탄화(flatten)\n",
    "        out = self.fc_layer(out)\n",
    "        return out\n",
    "\n",
    "class NeuralNetwork2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        output_channel = 512\n",
    "        input_channel = 3\n",
    "        self.output_channel = [int(output_channel / 8), int(output_channel / 4),\n",
    "        int(output_channel / 2), output_channel]  # [64, 128, 256, 512]\n",
    "        \n",
    "        self.ConvNet = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_channel, out_channels=self.output_channel[0], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),  # 64x16x50\n",
    "            nn.Conv2d(in_channels=self.output_channel[0], out_channels=self.output_channel[1], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(in_channels=self.output_channel[1], out_channels=self.output_channel[2],kernel_size=3, stride=1, padding=1), nn.ReLU(True),  # 256x8x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[2], out_channels=self.output_channel[2], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)),  # 256x4x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[2], out_channels=self.output_channel[2], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            nn.BatchNorm2d(self.output_channel[2]), nn.ReLU(True),  # 512x4x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[2], out_channels=self.output_channel[2], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            nn.BatchNorm2d(self.output_channel[2]), nn.ReLU(True),  # 512x4x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[2], out_channels=self.output_channel[2], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)),  # 256x4x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[2], out_channels=self.output_channel[3], kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.output_channel[3]), nn.ReLU(True),  # 512x4x25\n",
    "            nn.Conv2d(in_channels=self.output_channel[3], out_channels=self.output_channel[3], kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.output_channel[3]), nn.ReLU(True),\n",
    "            nn.MaxPool2d((2, 1), (2, 1)), \n",
    "            nn.Conv2d(in_channels=self.output_channel[3], out_channels=self.output_channel[3], kernel_size=3, stride=1, padding=1), nn.ReLU(True),\n",
    "            # nn.MaxPool2d((2, 1), (2, 1)))  # 512x1x24\n",
    "            nn.AdaptiveAvgPool2d((1, 1)))\n",
    "        self.fc_layer = nn.Sequential(\n",
    "        \t# [100,64*3*3] -> [100,100]\n",
    "            # nn.Linear(28672,4096),                                              \n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            # nn.Linear(4096,1000),  \n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(512,2),                             \n",
    "        )     \n",
    "    def forward(self, x):\n",
    "        out = self.ConvNet(x)\n",
    "        out = torch.flatten(out, 1) # 배치를 제외한 모든 차원을 평탄화(flatten)\n",
    "        out = self.fc_layer(out)\n",
    "        # nn.Linear(1024,2)\n",
    "        return out\n",
    "        \n",
    "    \n",
    "def file_recursively(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if((os.path.join(root,file).find(\".jpg\")) != -1):\n",
    "                list_root.append(os.path.join(root ,file))\n",
    "             \n",
    "def train_test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            y = y.to(device)\n",
    "            output = model.forward(x)\n",
    "            loss = loss_fn(output,y)\n",
    "            test_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= size\n",
    "    print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(dataloader.dataset), 100. * correct / len(dataloader.dataset)))\n",
    "    f.write('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(dataloader.dataset), 100. * correct / len(dataloader.dataset)))\n",
    "      \n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            y = y.to(device)\n",
    "            output = model.forward(x)\n",
    "            loss = loss_fn(output,y)\n",
    "            test_loss += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= size\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(dataloader.dataset), 100. * correct / len(dataloader.dataset)))\n",
    "    f.write('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(dataloader.dataset), 100. * correct / len(dataloader.dataset)))\n",
    "    return test_loss\n",
    "if __name__ == '__main__':\n",
    "                     \n",
    "    device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    "\n",
    "    print(f\"Using {device} device\")   \n",
    "\n",
    "    list_root = []\n",
    "    dic = {}\n",
    "    list_root_label = []\n",
    "\n",
    "    file_recursively('E:/동현_개인폴더/대회/USG제조혁신대회2차/train_img5')\n",
    "    label = pd.read_csv('E:/동현_개인폴더/대회/USG제조혁신대회2차/train.csv')\n",
    "    \n",
    "    img_end = []\n",
    "    img_end2 = []\n",
    "    \n",
    "    for i in list_root:\n",
    "        # img = imgs.imread(i)\n",
    "        img = Image.open(i).convert(\"RGB\")\n",
    "        # img = cv2.resize(img, dsize=(640,640), interpolation=cv2.INTER_LINEAR)\n",
    "        min_value = np.min(img)\n",
    "        max_value = np.max(img)\n",
    "        output = (img - min_value) / (max_value - min_value)\n",
    "        img_end.append(output)\n",
    "        img_end2.append(img)\n",
    "\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(img_end2, label['label'], test_size= 0.2, random_state= 33 ,shuffle=True)\n",
    "            \n",
    "            \n",
    "    #배치 사이즈 조정\n",
    "    batch_size = 2\n",
    "\n",
    "\n",
    "    transforms_train = transforms.Compose([ transforms.Resize((128, 128)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        # transforms.RandomRotation(10.)\n",
    "                                        ])\n",
    "\n",
    "    transforms_test = transforms.Compose([transforms.Resize((128,128)),\n",
    "                                        transforms.ToTensor()\n",
    "                                        ])\n",
    "\n",
    "\n",
    "    dataset_train = CustomDataset(x_train, y_train, transform=transforms_train)\n",
    "    dataset_valid = CustomDataset(x_valid, y_valid, transform=transforms_test)\n",
    "\n",
    "\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "    dataloader_valid = DataLoader(dataset_valid, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "    model = NeuralNetwork().to(device)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) \n",
    "\n",
    "\n",
    "    print(dataloader_train)\n",
    "\n",
    "    #-------------------------학습률 등의 파라미터 조정------------------------------------#\n",
    "    \n",
    "    \n",
    "    learning_rate = 1e-5\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    # dataloader_train = dataloader_train.squeeze(dim=0)\n",
    "    nb_epochs = 100\n",
    "    txtName = \"modelTrainLog\"\n",
    "    count = 1\n",
    "    best_loss = 10 ** 9 # 매우 큰 값으로 초기값 가정\n",
    "    patience_limit = 10 # 몇 번의 epoch까지 지켜볼지를 결정\n",
    "    patience_check = 0 # 현재 몇 epoch 연속으로 loss 개선이 안되는지를 기록\n",
    "    \n",
    "    \n",
    "    #------------------모델 학습 기록 생성-----------------------------------------------#\n",
    "    \n",
    "    if os.path.isfile(\"./model/{}.txt\".format(txtName)) != True:\n",
    "        f = open(\"./model/{}.txt\".format(txtName), \"w\")\n",
    "    else:\n",
    "        while(True):\n",
    "            if os.path.isfile(\"./model/{} ({}).txt\".format(txtName, count)) != True:\n",
    "                f = open(\"./model/{} ({}).txt\".format(txtName, count), \"w\")\n",
    "                break\n",
    "            else:\n",
    "                count += 1\n",
    "                \n",
    "                \n",
    "                \n",
    "    summary(model, (3,128, 128))\n",
    "    f.write(f\"batchsize: {batch_size:>d} epochs: {nb_epochs:>d}\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #------------------모델 학습-----------------------------------------------#\n",
    "\n",
    "    for epoch in range(nb_epochs + 1):\n",
    "        for batch, (x, y) in enumerate(dataloader_train):\n",
    "            x_train = x.to(device)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            y_train = y.to(device)\n",
    "            # H(x) 계산\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model.forward(x_train)\n",
    "            \n",
    "            loss = loss_func(pred, y_train)\n",
    "         \n",
    "            # 역전파\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch % 1000 == 0:\n",
    "                loss, current = loss.item(), (batch + 1) * len(x_train)\n",
    "                # print(f\"[epoch: {epoch:>5d}] loss: {loss:>7f}\")\n",
    "                print(f\"[epoch: {epoch:>d}] loss: {loss:>7f}  [{current:>5d}/{len(dataset_train.x_data):>5d}]\")\n",
    "                f.write(f\"[epoch: {epoch:>d}] loss: {loss:>7f}  [{current:>5d}/{len(dataset_train.x_data):>5d}]\\n\")\n",
    "        train_test(dataloader_train, model, loss_func)   \n",
    "        val_loss = test(dataloader_valid, model, loss_func)\n",
    "        model.eval()\n",
    "            \n",
    "        ### early stopping 여부를 체크하는 부분 ###\n",
    "        if val_loss > best_loss: # loss가 개선되지 않은 경우\n",
    "            patience_check += 1\n",
    "            if patience_check >= 5:\n",
    "                learning_rate = learning_rate / 2\n",
    "            if patience_check >= patience_limit: # early stopping 조건 만족 시 조기 종료\n",
    "                break\n",
    "        else:\n",
    "            best_loss = val_loss\n",
    "            patience_check = 0\n",
    "        PATH = './model/vgg_net_check_point.pth' #체크포인트\n",
    "        torch.save(model, PATH)\n",
    "        \n",
    "    PATH = './model/vgg_net.pth'\n",
    "    torch.save(model, PATH)\n",
    "    PATH = './model/vgg_best.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "        \n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    #최종 평가 결과 및 miscls 파악\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        count = 0\n",
    "        for x,y in dataloader_valid:\n",
    "            x = x.to(device)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            y = y.to(device)\n",
    "            outputs = model.forward(x)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += len(y)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            for i in range(0, len(y)):\n",
    "                if(predicted[i].item() != y[i]):\n",
    "                    plt.axis('off')\n",
    "                    tf = transforms.ToPILImage()\n",
    "                    img = tf(x[i])\n",
    "                    plt.imshow(img)\n",
    "                    plt.savefig('./mis2/{}_{}_{}.jpg'.format(count,y[i], predicted[i].item()),format='jpeg',bbox_inches=\"tight\", pad_inches = 0)\n",
    "                count += 1\n",
    "        print('Test Accuracy of the model on the {} test images: {} %'.format(total, 100 * correct / total))\n",
    "        f.write('Test Accuracy of the model on the {} test images: {} %\\n'.format(total, 100 * correct / total))\n",
    "    f.close()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "six",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
